{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import expanddouban\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "part1 : return a string corresponding to the URL of douban movie lists given category and location.\n",
    "观察豆瓣的url格式，写一个方法用来生成不同类型地区对应的URL\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def getMovieUrl(category, location):\n",
    "    if location == '全部地区':\n",
    "        url = 'https://movie.douban.com/tag/#/?sort=S&range=9,10&tags=电影,{}'.format(category)\n",
    "        return url\n",
    "    else:\n",
    "        url = 'https://movie.douban.com/tag/#/?sort=S&range=9,10&tags=电影,{},{}'.format(category, location)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "part 2： a function to help \"click\" load more button to get more items\n",
    "\n",
    "'''\n",
    "\n",
    "from selenium import webdriver\n",
    "import time \n",
    "\n",
    "\"\"\"\n",
    "url: the douban page we will get html from\n",
    "loadmore: whether or not click load more on the bottom \n",
    "waittime: seconds the broswer will wait after intial load and \n",
    "\"\"\" \n",
    "def getHtml(url, loadmore = False, waittime = 2):\n",
    "    browser = webdriver.Chrome('chromedriver')\n",
    "    browser.get(url)\n",
    "    time.sleep(waittime)\n",
    "    if loadmore:\n",
    "        while True:\n",
    "            try:\n",
    "                next_button = browser.find_element_by_class_name(\"more\")\n",
    "                next_button.click()\n",
    "                time.sleep(waittime)\n",
    "            except:\n",
    "                break\n",
    "    html = browser.page_source\n",
    "    browser.quit()\n",
    "    return html\n",
    "\n",
    "# for test\n",
    "#url = \"https://movie.douban.com/tag/#/?sort=S&range=9,10&tags=电影,剧情,美国\"\n",
    "#html = getHtml(url)\n",
    "#print(html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "part3: Movie class\n",
    "建一个类，接下来每一部电影会被当作一个对象来存储。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Movie:\n",
    "    # 电影名称\n",
    "    # 电影评分\n",
    "    # 电影类型\n",
    "    # 电影地区\n",
    "    # 电影页面链接\n",
    "    # 电影海报图片链接\n",
    "\n",
    "    def __init__(self, m_title, m_rate, m_category, m_location, m_url, m_picture_url):\n",
    "        self.name = m_title\n",
    "        self.rate = m_rate\n",
    "        self.category = m_category\n",
    "        self.location = m_location\n",
    "        self.info_link = m_url\n",
    "        self.cover_link = m_picture_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "part4: return a list of Movie objects with the given category and location.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def getMovies(category, location):\n",
    "    l = location\n",
    "    movie_object_list = []\n",
    "    html = getHtml(getMovieUrl(category, location), loadmore=True, waittime=3)\n",
    "    \n",
    "    # Use BeautifulSoup to parse the HTML doc\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    webpage = soup.find(id=\"content\").find(class_=\"list-wp\").find_all(\"a\", recursive=False)\n",
    "\n",
    "    for mov in webpage:\n",
    "        title = mov.find(class_=\"title\").string\n",
    "        rate = mov.find(class_=\"rate\").string\n",
    "        if rate == None:\n",
    "            rate = '该电影尚无评分'\n",
    "        url = mov.get(\"href\")\n",
    "        if url == None:\n",
    "            url = '该电影尚无豆瓣链接'\n",
    "        cover_url = mov.find(\"img\").get(\"src\")\n",
    "        movie = Movie(title, rate, category, l, url, cover_url)\n",
    "        movie_object_list.append(movie)\n",
    "    return movie_object_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "part5: Output to .csv files\n",
    "从网页上选取你最爱的三个电影类型，然后获取每个地区的电影信息后，我们可以获得一个包含三个类型、所有地区，评分超过9分的完整电影对象的列表。\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "get the location list from webpage\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def getlocationlist():\n",
    "    l_list = []\n",
    "    uuurl = getMovieUrl(\"全部类型\", \"全部地区\")\n",
    "    hhhtml = expanddouban.getHtml(uuurl, loadmore=True, waittime=3)\n",
    "    sssoup = BeautifulSoup(hhhtml, \"html.parser\")\n",
    "    wwwebpage = sssoup.find(id='content').find(class_='tags').find(class_='category').next_sibling\n",
    "    for c in wwwebpage.next_sibling:\n",
    "        lllocation = c.find(class_='tag').string\n",
    "        if lllocation != '全部地区':\n",
    "            l_list.append(lllocation)\n",
    "    return l_list\n",
    "\n",
    "\n",
    "location_list = getlocationlist()\n",
    "\n",
    "story_list = []\n",
    "crime_list = []\n",
    "fiction_list = []\n",
    "\n",
    "for i in range(len(location_list)):\n",
    "    current_list1 = getMovies(\"犯罪\", location_list[i])\n",
    "    current_list2 = getMovies(\"剧情\", location_list[i])\n",
    "    current_list3 = getMovies(\"科幻\", location_list[i])\n",
    "    crime_list += current_list1\n",
    "    story_list += current_list2\n",
    "    fiction_list += current_list3\n",
    "\n",
    "all_movie_list = story_list + crime_list + fiction_list\n",
    "\n",
    "\n",
    "def writeToCsv(m_list):\n",
    "    with open('movies.csv', 'w', newline='', encoding='utf-8-sig') as f:\n",
    "        f.write(\"名称,评分,种类,地区,链接,海报\\n\")\n",
    "        for l in m_list:\n",
    "            f.write(\"{},{},{},{},{},{}\\n\".format(l.name.replace('，', '~'), l.rate, l.category, l.location, l.info_link,\n",
    "                                                 l.cover_link))\n",
    "\n",
    "\n",
    "writeToCsv(all_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "part6:统计你所选取的每个电影类别中，数量排名前三的地区有哪些，分别占此类别电影总数的百分比为多少？\n",
    "\n",
    "你可能需要自己把这个任务拆分成多个步骤，统计每个类别的电影个数，统计每个类别每个地区的电影个数，排序找到最大值，做一定的数学运算等等，相信你一定可以的！\n",
    "\n",
    "请将你的结果输出文件 output.txt\n",
    "\n",
    "\"\"\"\n",
    "with open('movies.csv', 'r', encoding='utf-8-sig') as m:\n",
    "    csv_reader = csv.reader(m)\n",
    "    movies_list = list(csv_reader)\n",
    "\n",
    "story_count = 0\n",
    "fiction_count = 0\n",
    "crime_count = 0\n",
    "story_l = []\n",
    "fiction_l = []\n",
    "crime_l = []\n",
    "\n",
    "for i in range(len(movies_list)):\n",
    "    if movies_list[i][2] == \"剧情\":\n",
    "        story_count += 1\n",
    "        story_l.append(movies_list[i][3])\n",
    "    elif movies_list[i][2] == \"科幻\":\n",
    "        fiction_count += 1\n",
    "        fiction_l.append(movies_list[i][3])\n",
    "    else:\n",
    "        crime_count += 1\n",
    "        crime_l.append(movies_list[i][3])\n",
    "a = dict(Counter(story_l))\n",
    "b = dict(Counter(fiction_l))\n",
    "c = dict(Counter(crime_l))\n",
    "\n",
    "sorted_a = sorted(a.items(), key=operator.itemgetter(1))\n",
    "sorted_b = sorted(b.items(), key=operator.itemgetter(1))\n",
    "sorted_c = sorted(c.items(), key=operator.itemgetter(1))\n",
    "\n",
    "with open('output-stats.txt', 'w', newline='', encoding='utf-8-sig') as ff:\n",
    "    aa = \"{}电影类别中，数量排名前三的地区有为{} {} {}，分别占此类别电影总数的百分比为{}% {}% {}%\\n\".format(\"剧情\", sorted_a[-1][0], sorted_a[-2][0],sorted_a[-3][0],round((sorted_a[-1][1] / story_count * 100),2),round((sorted_a[-2][1] / story_count * 100),2),round((sorted_a[-3][1] / story_count * 100),2))\n",
    "    bb = \"{}电影类别中，数量排名前三的地区有为{} {} {}，分别占此类别电影总数的百分比为{}% {}% {}%\\n\".format(\"科幻\", sorted_b[-1][0], sorted_b[-2][0],sorted_b[-3][0], round((sorted_b[-1][1] / fiction_count * 100), 2), round((sorted_b[-2][1] / fiction_count * 100), 2), round((sorted_b[-3][1] / fiction_count * 100), 2))\n",
    "    cc = \"{}电影类别中，数量排名前三的地区有为{} {} {}，分别占此类别电影总数的百分比为{}% {}% {}%\".format(\"犯罪\", sorted_c[-1][0], sorted_c[-2][0],sorted_c[-3][0],round((sorted_c[-1][1] / crime_count * 100),2),round((sorted_c[-2][1] / crime_count * 100),2),round((sorted_c[-3][1] / crime_count * 100),2))\n",
    "    ff.write(aa)\n",
    "    ff.write(bb)\n",
    "    ff.write(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
